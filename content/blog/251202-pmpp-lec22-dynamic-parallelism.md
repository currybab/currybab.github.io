+++
title = "Pmpp Lec22 Dynamic Parallelism"
date = "2025-12-02T20:37:40+09:00"

#
# description is optional
#
# description = "An optional description for SEO. If not provided, an automatically created summary will be used."

tags = ["pmpp", "cuda", "gpu"]
+++

Source: [Lecture 22 - Dynamic Parallelism](https://www.youtube.com/watch?v=R3d_ECmHAiI)

## Dynamic Parallelism

- ë™ì  ë³‘ë ¬ ì²˜ë¦¬ëŠ” GPUì—ì„œ ì‹¤í–‰ ì¤‘ì¸ ìŠ¤ë ˆë“œê°€ ìƒˆë¡œìš´ ê·¸ë¦¬ë“œë¥¼ ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” ê¸°ëŠ¥ì„.

![dynamic parallelism](https://img.buidl.day/blog/dynamic-parallelism.png)

## Nested Parallelism

- ë³‘ë ¬ ì²˜ë¦¬ê°€ ìˆê³ , ê° ë³‘ë ¬ ì²˜ë¦¬ ë‹¨ìœ„ ë‚´ì—ì„œ ë” ë§ì€ ë³‘ë ¬ ì²˜ë¦¬ê°€ ìˆì„ ë•Œ ìœ ìš©í•¨.
- ê° ìŠ¤ë ˆë“œê°€ ì‹¤í–‰í•˜ë©´ì„œ ë³‘ë ¬í™” í•  ìˆ˜ ìˆëŠ” ë” ë§ì€ ì‘ì—…ì„ ë°œê²¬í•˜ëŠ” ê²½ìš°, ì¦‰ ì¤‘ì²©ëœ ë³‘ë ¬ì„±ì„ ê°€ì§„ í”„ë¡œê·¸ë˜ë°ì„ í•  ë•Œ ìœ ìš©í•¨.

- ì¤‘ì²©ëœ ì‘ì—…ì˜ ì–‘ì„ ì•Œ ìˆ˜ ì—†ì„ ë•Œ ë”ìš± ìœ ìš©í•¨. ê³ ì •ëœ ì–‘ì„ ë¯¸ë¦¬ ì‹¤í–‰í•˜ëŠ” ê²ƒì´ ì–´ë µê¸° ë•Œë¬¸ì—.

## Applications of Dynamic Parallelism

- ì¤‘ì²© ë³‘ë ¬ ì²˜ë¦¬ì˜ ì–‘ì„ ì•Œ ìˆ˜ ì—†ëŠ” ë‘ê°€ì§€ ì£¼ìš” ì´ìœ ê°€ ìˆìŒ.
    - ì¤‘ì²©ëœ ë³‘ë ¬ ì‘ì—…ì´ ë¶ˆê·œì¹™í•œ ê²½ìš°(ìŠ¤ë ˆë“œë§ˆë‹¤ ë‹¤ë¦„)
        - ì˜ˆì‹œë¡œëŠ” ê·¸ë˜í”„ ì•Œê³ ë¦¬ì¦˜ì´ ìˆìŒ. ê° vertexë§ˆë‹¤ ë‹¤ë¥¸ ìˆ˜ì˜ ì´ì›ƒì´ ìˆìŒ.
        - ë‹¤ë¥¸ ì˜ˆì‹œë¡œëŠ” ë² ì§€ì–´ ê³¡ì„ ì´ ìˆìŒ. ì ì„ ì´ìš©í•˜ì—¬ ì„ ì„ ê·¸ë¦¬ëŠ” ì‘ì—…ì„.
            - ì„ ë“¤ì„ ê·¸ë¦¬ê¸°ìœ„í•´ ì„ ì˜ ê³¡ë¥ ì— ë”°ë¼ ì„ ì„ ê·¸ë¦¬ëŠ”ë° í•„ìš”í•œ ì ì˜ ìˆ˜ê°€ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŒ.
    - ì¤‘ì²©ëœ ë³‘ë ¬ ì‘ì—…ì´ ì¬ê¸°ì ì¸ ê²½ìš°(ì•Œìˆ˜ ì—†ëŠ” ê¹Šì´ë¥¼ ê°€ì§), ìŠ¤ë ˆë“œë§ˆë‹¤ ì¬ê·€ë¥¼ í• ìˆ˜ë„ ìˆê³  ì•ˆí•  ìˆ˜ ë„ ìˆìŒ.
        - tree traversal alogithm
        - ë¶„í•  ì •ë³µ ì•Œê³ ë¦¬ì¦˜(í€µì†ŒíŠ¸) - ë” ë‚˜ëˆ ì•¼ í• ì§€ ë§ì§€ ì •í•´ì§€ì§€ ì•ŠìŒ.

## Dynamic Parallelism API

- ì»¤ë„ì„ í˜¸ì¶œí•˜ì—¬ ê·¸ë¦¬ë“œë¥¼ ì‹¤í–‰í•˜ëŠ” ì¥ì¹˜ ì½”ë“œëŠ” í˜¸ìŠ¤íŠ¸ ì½”ë“œì™€ ë™ì¼í•¨.
- ë§ì€ ìŠ¤ë ˆë“œë“¤ì´ ìˆê¸° ë•Œë¬¸ì— ëª¨ë“  ì‹¤í–‰ì´ ë™ì‹œì— ì‹¤í–‰ë  ìˆ˜ ëŠ” ì—†ìŒ. ë”°ë¼ì„œ ì¥ì¹˜ëŠ” ì´ëŸ¬í•œ ì‹¤í–‰ì„ ìœ„í•œ ìƒíƒœë¥¼ ì‹¤í–‰í•  ì°¨ë¡€ê°€ ë ë•Œê¹Œì§€ ë²„í¼ì— ì €ì¥ í•´ì•¼í•¨. 
- ì•„ì§ ì‹¤í–‰ë˜ì§€ ì•Šì€ ê·¸ë¦¬ë“œ launchë¥¼ ë²„í¼ë§í•˜ë ¤ë©´ ë©”ëª¨ë¦¬ê°€ í•„ìš”í•¨.
    - ë©”ëª¨ë¦¬ ì œí•œì´ ìˆê¸° ë•Œë¬¸ì— ì œê³µí•  ì‹œì‘ íšŸìˆ˜ì— ëŒ€í•œ ì‹¤ì œë¡œ ì œí•œì´ ìˆìŒ. ê°€ì§ˆ ìˆ˜ ìˆëŠ” ë™ì  ì‹¤í–‰ì˜ ìˆ˜ì— ì œí•œì´ ìˆìŒì„ ì˜ë¯¸í•¨.
    - ë™ì  ì‹¤í–‰ íšŸìˆ˜ì˜ ì œí•œì€ ë³´ë¥˜ ì¤‘ì¸ ì‹¤í–‰ ìˆ˜(pending launch count)ë¼ê³  í•¨.
    - ê¸°ë³¸ì ìœ¼ë¡œ, ëŸ°íƒ€ì„ì€ 2048ê°œì˜ ê·¸ë¦¬ë“œë¥¼ ë™ì ìœ¼ë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆê²Œ ì§€ì›í•˜ê³  ì œí•œì„ ë„˜ìœ¼ë©´ ì—ëŸ¬ë¥¼ ì¼ìœ¼í‚´.
    - 2048ê°œ ì´ìƒì˜ ì‹¤í–‰ì´ í•„ìš”í•˜ë©´ ì œí•œì„ ëŠ˜ë ¤ ëŸ°íƒ€ì„ì— ë” ë§ì€ ë©”ëª¨ë¦¬ë¥¼ í• ë‹¹í•˜ë„ë¡ ì§€ì‹œí•  ìˆ˜ ìˆìŒ.
        - `cudaDeviceSetLimit(cudaLimitDevRuntimePendingLaunchCount, < new limit >);`
        - 2048ê°œë§Œí•´ë„ ì •ìƒì ì¸ ìƒí™©ì€ ì•„ë‹˜. ì´ ì œí•œì„ ëŠ˜ë¦¬ëŠ” ê²ƒì€ ì–´ì°¨í”¼ í•˜ì§€ ë§ì•„ì•¼í•  ì¼ì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŒ.
  

## í”„ë¡ í‹°ì–´ë¥¼ ì‚¬ìš©í•œ BFS

![bfs frontier](https://img.buidl.day/blog/dynamic-parallelism-bfs.png)


```c
    // ì´ì›ƒì˜ ìˆ˜ë§Œí¼ ë°˜ë³µí•˜ëŠ” ëŒ€ì‹  ê° ì´ì›ƒì— ëŒ€í•´ ìŠ¤ë ˆë“œë¥¼ ì‹¤í–‰í•  ê²ƒ
    
    __global__ void bfs_child_kernel(CSRGraph, csrGraph, unsigned int* level, unsigned int* currFrontier, unsigned int numPrevFrontier, unsigned int* numCurrFrontier, unsigned int currLevel, unsigned int numNeighbors, unsigned int start) {
        unsigned int i = blockIdx.x * blockDim.x + threadIdx.x;
        if (i < numNeighbors) {
            unsigned int edge = start + i;
            unsigned int neighbor = csrGraph.dst[edge];
            if (atomicCAS(&level[neighbor], UINT_MAX, currLevel) == UINT_MAX) { // ë‹¤ë¥¸ ìŠ¤ë ˆë“œì—ì„œ ë™ì¼í•œ ì •ì ì— ëŒ€í•´ ë°©ë¬¸í–ˆì„ ê²½ìš°
                unsigned int currFrontierIdx = atomicAdd(numCurrFrontier, 1);
                currFrontier[currFrontierIdx] = neighbor;
            }
        }
    }

    __global__ void bfs_kernel(CSRGraph, csrGraph, unsigned int* level, unsigned int* prevFrontier, unsigned int* currFrontier, unsigned int numPrevFrontier, unsigned int* numCurrFrontier, unsigned int currLevel) {
        unsigned int i = blockIdx.x * blockDim.x + threadIdx.x;
        if (i < numPrevFrontier) {
            unsigned int vertex = prevFrontier[i];
            unsigned int start = csrGraph.srcPtrs[vertex];
            unsigned int numNeighbors = csrGraph.srcPtrs[vertex + 1] - start;
            unsigned int numThreadsPerBloc = 1024;
            unsigned int numBlocks = (numNeighbors + numThreadsPerBloc - 1) / numThreadsPerBloc;
            bfs_child_kernel<<< numBlocks, numThreadsPerBloc >>>(csrGraph, level, currFrontier, numPrevFrontier, numCurrFrontier, currLevel, numNeighbors, start);
        }
    }

    void bfs_levels(CSRGraph, csrGraph, unsigned int* level, unsigned int* prevFrontier, unsigned int* currFrontier, unsigned int* numCurrFrontier) {
        unsigned int numPrevFrontier = 1;
        unsigned int numThreadsPerBlock = 256;
        cudaDeviceSetLimit(cudaLimitDevRuntimePendingLaunchCount, csrGraph.numVertices);
        for (unsigned int currLevel = 1; numPrevFrontier > 0; currLevel++) {
            // Visit vertices in previous frontier
            cudaMemset(numCurrFrontier, 0, sizeof(unsigned int));
            unsigned int numBlocks = (numPrevFrontier + numThreadsPerBlock - 1) / numThreadsPerBlock;
            bfs_child_kernel<<< numBlocks, numThreadsPerBlock >>>(csrGraph, level, prevFrontier, currFrontier, numPrevFrontier, numCurrFrontier, currLevel);
            cudaDeviceSynchronize();
            // Swap buffers
            unsigned int* temp = prevFrontier;
            prevFrontier = currFrontier;
            currFrontier = temp;
            cudaMemcpy(&numPrevFrontier, numCurrFrontier, sizeof(unsigned int), cudaMemcpyDeviceToHost);
        }
        cudaDeviceSynchronize();
    }
```
- 14.45ms -> 130.59ms 10x slower
- ê·¸ë¦¬ë“œë“¤ ê°ê°ì´ ë¹„êµì  ë„ˆë¬´ ì‘ì•„ì„œ ì˜¤íˆë ¤ ì„±ëŠ¥ì„ ë°©í•´í•¨.

## Streams

- ìš°ë¦¬ê°€ ìŠ¤íŠ¸ë¦¼ì„ ì§€ì •í•˜ì§€ ì•Šìœ¼ë©´ ê¸°ë³¸ì ìœ¼ë¡œ default streamì— ë“¤ì–´ê°.
- ë””ë°”ì´ìŠ¤ì—ì„œ ì‹¤í–‰ë  ë•Œ, ë™ì¼í•œ ë¸”ë¡ì— ìˆëŠ” ìŠ¤ë ˆë“œë“¤ì€ ê°™ì€ default streamì„ ê³µìœ í•¨.
    - ê°™ì€ ë¸”ë¡ì— ìˆëŠ” ìŠ¤ë ˆë“œë“¤ì— ì˜í•œ ì‹¤í–‰ì€ ì§ë ¬í™”ë¨.
    - ê¸°ë³¸ ìŠ¤íŠ¸ë¦¼ì„ ì‚¬ìš©í•˜ëŠ” ëŒ€ì‹  ìŠ¤ë ˆë“œ ë³„ë¡œ ìŠ¤íŠ¸ë¦¼ì„ ì‚¬ìš©í•˜ë©´ ë³‘ë ¬í™” í•  ìˆ˜ ìˆìŒ.

## Per-Thread Stream

- ê° ìŠ¤ë ˆë“œë§ˆë‹¤ ë‹¤ë¥¸ ìŠ¤íŠ¸ë¦¼ì„ ìƒì„±í•˜ê³  ê° ìŠ¤ë ˆë“œê°€ ìì²´ ìŠ¤íŠ¸ë¦¼ìœ¼ë¡œ ì‹œì‘í•˜ê²Œ í•¨ìœ¼ë¡œì¨ ë³‘ë ¬ì„±ì„ ê°œì„ í•  ìˆ˜ ìˆìŒ.
    - ë°©ì‹ 1: hostì—ì„œì™€ ê°™ì´ stream APIë¥¼ ì‚¬ìš©í•¨.
    - ë°©ì‹ 2: ì»´íŒŒì¼ëŸ¬ í”Œë˜ê·¸ë¥¼ ì‚¬ìš©í•¨ `--default-stream per-thread`
- ê²°ê³¼: 130.59ms -> 125.51ms ì•½ê°„ ê°œì„ ë¨. ì‹¤ì œë¡œ ì„±ëŠ¥ì„ ì œí•œí•˜ëŠ” ê²ƒì´ ë‹¤ë¥¸ê²ƒì„ì„ ìƒê°í•  ìˆ˜ ìˆìŒ.

## Optimizationss

- í”í•œ í•¨ì •: 
    - ìš°ë¦¬ê°€ ì•„ì£¼ ì‘ì€ ê·¸ë¦¬ë“œë¥¼ ì‹¤í–‰í•˜ëŠ” ê²½ìš° ì˜¤ë²„í—¤ë“œê°€ ê°€ì¹˜ê°€ ì—†ì„ ê²ƒì´ë‹¤.(ìˆœì°¨ì ìœ¼ë¡œ í•˜ëŠ”ê²ƒì´ íš¨ìœ¨ì ì¼ ê²ƒ)
    - ë„ˆë¬´ ë§ì€ ê·¸ë¦¬ë“œë¥¼ ì‹¤í–‰í•˜ë©´ GPUì—ì„œ í ì§€ì—°ì´ ì¼ì–´ë‚¨.
- ìµœì í™”: ì‹¤í–‰ì— ì„ê³„ê°’ì„ ì ìš©í•¨.
    - ì˜¤ë²„í—¤ë“œë¥¼ ê°ìˆ˜í•  ë§Œí•œ í° ê·¸ë¦¬ë“œë§Œ ì‹¤í–‰í•˜ê³  ë‚˜ë¨¸ì§€ëŠ” ì§ë ¬í™”í•¨.
    - ê·¸ë˜í”„ì˜ ì •ì ë“¤ì˜ ì°¨ìˆ˜ê°€ ì–´ë–»ê²Œ ë¶„í¬ ë˜ì—ˆëŠëƒì— ë”°ë¼ ì„ê³„ê°’ì€ ë‹¬ë¼ì§ˆ ê²ƒ.(íŠœë‹ í¬ì¸íŠ¸)
    - ì ìš© í›„ 6.9msë¡œ ëŒ€í­ ê°œì„ ë¨ ğŸš€
- ìµœì í™”: ì‹¤í–‰ì„ ì§‘ê³„í•˜ëŠ” ê²ƒ (aggregate launches)
      - í•˜ë‚˜ì˜ ìŠ¤ë ˆë“œê°€ ì—¬ëŸ¬ ìŠ¤ë ˆë“œì˜ ì‘ì—…ì„ ìˆ˜ì§‘í•˜ë„ë¡ í•˜ê³  ê·¸ë“¤ì„ ëŒ€ì‹ í•˜ì—¬ ë‹¨ì¼ ìŠ¤ë ˆë“œë¥¼ ì‹¤í–‰í•¨.
      - ê½¤ ë³µì¡í•´ì„œ ë…¼ë¬¸ì´ ìˆë‹¤ê³  í•¨.

```c
    __global__ void bfs_kernel(CSRGraph, csrGraph, unsigned int* level, unsigned int* prevFrontier, unsigned int* currFrontier, unsigned int numPrevFrontier, unsigned int* numCurrFrontier, unsigned int currLevel) {
        unsigned int i = blockIdx.x * blockDim.x + threadIdx.x;
        if (i < numPrevFrontier) {
            unsigned int vertex = prevFrontier[i];
            unsigned int start = csrGraph.srcPtrs[vertex];
            unsigned int numNeighbors = csrGraph.srcPtrs[vertex + 1] - start;
            // ì„ê³„ê°’ì„ ë„˜ìœ¼ë©´ ê·¸ë¦¬ë“œë¥¼ ì‹¤í–‰í•˜ê³  ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ ì§ë ¬í™”í•¨.
            if (numNeighbors > 1200) {
                unsigned int numThreadsPerBloc = 1024;
                unsigned int numBlocks = (numNeighbors + numThreadsPerBloc - 1) / numThreadsPerBloc;
                bfs_child_kernel<<< numBlocks, numThreadsPerBloc >>>(csrGraph, level, currFrontier, numPrevFrontier, numCurrFrontier, currLevel, numNeighbors, start);
            } else {
                for (unsigned int i = 0; i < numNeighbors; i++) {
                    unsigned int edge = start + i;
                    unsigned int neighbor = csrGraph.dst[edge];
                    if (atomicCAS(&level[neighbor], UINT_MAX, currLevel) == UINT_MAX) { // ë‹¤ë¥¸ ìŠ¤ë ˆë“œì—ì„œ ë™ì¼í•œ ì •ì ì— ëŒ€í•´ ë°©ë¬¸í–ˆì„ ê²½ìš°
                        unsigned int currFrontierIdx = atomicAdd(numCurrFrontier, 1);
                        currFrontier[currFrontierIdx] = neighbor;
                    }
                }
            }
        }
    }
```

## Offloading Driver Code

- ì—¬ê¸°ì„œ Driver Codeë€, ì¥ì¹˜ë“œë¼ì´ë²„ê°€ ì•„ë‹ˆê³  ê¸°ë³¸ì ìœ¼ë¡œ ì „ì²´ ê³„ì‚°ì„ êµ¬ë™í•˜ëŠ” í•¨ìˆ˜ë¥¼ ëœ»í•¨.
- ì–´ë–¤ ì–´í”Œë¦¬ì¼€ì´ì…˜ì—ì„œëŠ” ê³„ì‚°ì„ êµ¬ë™í•˜ëŠ” í˜¸ìŠ¤íŠ¸ ì½”ë“œê°€ ì‹¤í–‰ê°„ì— ìŠ¤ë ˆë“œë“¤ì„ ë™ê¸°í™” í•˜ê¸° ìœ„í•´ì„œ ì—¬ëŸ¬ê°œì˜ ì—°ì†ì ì¸ ê·¸ë¦¬ë“¤ ì‹¤í–‰í•œë‹¤.
    - BFSë„ ë‹¤ìŒ ë ˆë²¨ë¡œ ë„˜ì–´ê°€ê¸° ì „ì— ì´ì „ ë ˆë²¨ì˜ ì‘ì—…ì„ ì™„ë£Œí•´ì•¼ í•¨.
- ë™ì ë³‘ë ¬ì²˜ë¦¬ì˜ ë˜ ë‹¤ë¥¸ ì‘ìš©ì€ ì´ ë“œë¼ì´ë²„ ì½”ë“œë¥¼ ë””ë°”ì´ìŠ¤ë¡œ ì˜¤í”„ë¡œë“œí•˜ëŠ” ê²ƒ.
    - ì£¼ìš” ì¥ì ì€ í˜¸ìŠ¤íŠ¸ê°€ ë‹¤ë¥¸ ì¼ì„ í•  ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” ê²ƒì„.
    - ì‹¤ì œë¡œ ì„±ëŠ¥ í–¥ìƒì„ ê¸°ëŒ€í•˜ê¸°ëŠ” ì–´ë ¤ì›€. í•˜ì§€ë§Œ CPUë¥¼ í™•ë³´í•  ìˆ˜ ìˆìŒ.

```c
    __global__ void bfs_levels_kernel(CSRGraph, csrGraph, unsigned int* level, unsigned int* prevFrontier, unsigned int* currFrontier, unsigned int* numCurrFrontier) {
        unsigned int numPrevFrontier = 1;
        unsigned int numThreadsPerBlock = 256;
        for (unsigned int currLevel = 1; numPrevFrontier > 0; currLevel++) {
            // Visit vertices in previous frontier
            *numCurrFrontier = 0;
            unsigned int numBlocks = (numPrevFrontier + numThreadsPerBlock - 1) / numThreadsPerBlock;
            bfs_child_kernel<<< numBlocks, numThreadsPerBlock >>>(csrGraph, level, prevFrontier, currFrontier, numPrevFrontier, numCurrFrontier, currLevel);
            cudaDeviceSynchronize();
            
            // Swap buffers
            unsigned int* temp = prevFrontier;
            prevFrontier = currFrontier;
            currFrontier = temp;
            numPrevFrontier = *numCurrFrontier;
        }
    }

    void bfs_levels(CSRGraph, csrGraph, unsigned int* level, unsigned int* prevFrontier, unsigned int* currFrontier, unsigned int* numCurrFrontier) {
        cudaDeviceSetLimit(cudaLimitDevRuntimePendingLaunchCount, csrGraph.numVertices);
        bfs_levels_kernel<<< 1, 1 >>>(csrGraph, level, prevFrontier, currFrontier, numCurrFrontier);
        cudaDeviceSynchronize();
    }
```

## Memory Visibility

- ë¶€ëª¨ ìŠ¤ë ˆë“œê°€ ê¸€ë¡œë²Œ ë©”ëª¨ë¦¬ì— ì“°ê³  ì‹¤í–‰ì„ ìˆ˜í–‰í•˜ë©´ ìì‹ ê·¸ë¦¬ë“œì˜ ìŠ¤ë ˆë“œëŠ” ì „ì—­ ë©”ëª¨ë¦¬ì˜ ë³€ê²½ì‚¬í•­ì„ ë³¼ ìˆ˜ ìˆìŒ.
    - ê·¸ë¦¬ë“œì˜ ìì‹ ìŠ¤ë ˆë“œì— ì˜í•´ ìˆ˜í–‰ë˜ëŠ” ì‘ì—…ì€ ìì‹ì´ ëŒì•„ì˜¤ê³  ë¶€ëª¨ê°€ ë™ê¸°í™”ëœ í›„ ë¶€ëª¨ì—ê²Œ ë³´ì¼ ê²ƒì„.
- ìŠ¤ë ˆë“œì˜ ë¡œì»¬ ë©”ëª¨ë¦¬ì™€ ë¸”ë¡ì˜ ê³µìœ  ë©”ëª¨ë¦¬ëŠ” ìì‹ ìŠ¤ë ˆë“œê°€ ì ‘ê·¼í•  ìˆ˜ ì—†ìŒ.
    - ë¶€ëª¨ê°€ ì‹œì‘í•œ ìì‹ ìŠ¤ë ˆë“œê°€ ë‹¤ë¥¸ SM ì—ì„œ ì‹¤í–‰ ë  ìˆ˜ ìˆê¸° ë•Œë¬¸ì—

## ì¤‘ì²© ê¹Šì´ (Nesting Depth)

- ì¤‘ì²© ê¹Šì´ëŠ” ë™ì  ì‹¤í–‰ ê·¸ë¦¬ë“œë“¤ì´ ì–¼ë§ˆë‚˜ ê¹Šê²Œ ì‹¤í–‰ ë˜ì—ˆëŠ”ì§€ì— ëŒ€í•œ ê°’ì„.
- í•˜ë“œì›¨ì–´ì— ì˜í•´ ì œí•œì´ ìˆìœ¼ë©° ì¼ë°˜ì ìœ¼ë¡œ 24ì„.
